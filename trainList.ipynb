{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas.api.types as ptypes\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import datetime\n",
    "import matplotlib\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_f_APCPsurface1HourForecast\nn_f_APCPsurface1HourForecast\n"
    }
   ],
   "source": [
    "normalize = False\n",
    "prediction_trend_data = [] \n",
    "input_numeric_columns = []\n",
    "input_categorical_columns = []\n",
    "output_columns = []\n",
    "\n",
    "dfOriginal = pd.read_csv('data/revisedDataSectionsRemoved.csv', parse_dates=['date'])\n",
    "df = dfOriginal\n",
    "all_columns = list(df)\n",
    "numeric_regex = re.compile(\"n_*\")\n",
    "input_numeric_columns = list(filter(numeric_regex.match, all_columns))\n",
    "print(input_numeric_columns[0])\n",
    "for item in input_numeric_columns:\n",
    "    print(item)\n",
    "    break\n",
    "categorical_regex = re.compile(\"c_*\")                               \n",
    "input_categorical_columns = list(filter(categorical_regex.match, all_columns))\n",
    "output_regex = re.compile(\"o_*\")                               \n",
    "output_columns = list(filter(output_regex.match, all_columns))\n",
    "metadata_columns = [\"Lat\", \"Lon\", \"regionToJoin\", \"date\"]\n",
    "df = df[input_numeric_columns+input_categorical_columns+output_columns+prediction_trend_data+metadata_columns]\n",
    "\n",
    "if(normalize):\n",
    "    #normalize data; not necessary for xgboost\n",
    "    scaler = Normalizer()\n",
    "    dontNormalize = input_categorical_columns + output_columns + prediction_trend_data + metadata_columns\n",
    "    df.loc[:, ~df.columns.isin(dontNormalize)] = scaler.fit_transform(df.loc[:, ~df.columns.isin(dontNormalize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yColumnlist = []\n",
    "outputList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work towards making classes so the code is much more concise\n",
    "\n",
    "class Target:\n",
    "    name = ''\n",
    "\n",
    "    x_train = pd.DataFrame()\n",
    "    x_test = pd.DataFrame()\n",
    "    x_val = pd.DataFrame()\n",
    "\n",
    "    y_train = pd.DataFrame()\n",
    "    y_test = pd.DataFrame()\n",
    "    y_val = pd.DataFrame()\n",
    "\n",
    "    y_data = pd.DataFrame()\n",
    "\n",
    "    y_column = []\n",
    "    y_data = []\n",
    "    labels = []\n",
    "    def __init__(self, featureName, columnName, df):\n",
    "        name = featureName\n",
    "        y_column = [columnName]\n",
    "        y_data = df[y_column + metadata_columns]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y_data, stratify=y_data[columnName], test_size=0.20, random_state=1)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify=y_train[columnName], test_size=0.20, random_state=1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Target('o_day1DangerAboveTreeline', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12057 train examples\n3015 validation examples\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       n_f_APCPsurface1HourForecast  n_f_10mWindSpeed1HourForecast  \\\n8087                          0.000                       5.003431   \n17256                         0.250                       1.521547   \n12637                         5.125                       5.506617   \n17425                         4.625                       2.886101   \n10113                         0.000                       4.083557   \n\n       n_f_APCPsurface2HourForecast  n_f_10mWindSpeed2HourForecast  \\\n8087                          0.000                       4.714842   \n17256                         0.375                       1.485751   \n12637                         5.375                       5.804362   \n17425                         6.625                       3.994727   \n10113                         0.000                       3.985551   \n\n       n_f_APCPsurface3HourForecast  n_f_10mWindSpeed3HourForecast  \\\n8087                          0.000                       4.466812   \n17256                         1.125                       0.849602   \n12637                         5.375                       5.406490   \n17425                         6.625                       3.994727   \n10113                         0.000                       3.985551   \n\n       n_f_APCPsurface4HourForecast  n_f_10mWindSpeed4HourForecast  \\\n8087                          0.000                       3.891302   \n17256                         2.625                       0.214329   \n12637                         5.375                       5.092266   \n17425                         8.500                       4.588402   \n10113                         0.000                       4.181581   \n\n       n_f_APCPsurface5HourForecast  n_f_10mWindSpeed5HourForecast  ...  \\\n8087                          0.000                       3.608659  ...   \n17256                         4.625                       0.428978  ...   \n12637                         5.500                       4.548136  ...   \n17425                         8.500                       4.588402  ...   \n10113                         0.000                       4.181581  ...   \n\n       n_r_Prev1dayMinTemp10InPast  n_r_Prev1DayPrecip10InPast  \\\n8087                         17.96                       0.000   \n17256                        28.58                      90.625   \n12637                        28.76                      59.875   \n17425                        21.92                     339.500   \n10113                         0.68                       0.000   \n\n       n_r_Prev24HoursPrecipAsRainTotalIn10InPast  \\\n8087                                          0.0   \n17256                                         0.0   \n12637                                         0.0   \n17425                                         0.0   \n10113                                         0.0   \n\n       n_r_SNOWDAS_SnowDepth_mm10InPast  n_r_SNOWDAS_SWE_mm10InPast  \\\n8087                                179                          38   \n17256                                 0                           0   \n12637                                37                           9   \n17425                               543                         142   \n10113                              2266                         665   \n\n       n_r_SNOWDAS_SnowmeltRunoff_micromm10InPast  \\\n8087                                            0   \n17256                                           0   \n12637                                         133   \n17425                                        1064   \n10113                                           0   \n\n       n_r_SNOWDAS_Sublimation_micromm10InPast  \\\n8087                                        10   \n17256                                        0   \n12637                                        7   \n17425                                        4   \n10113                                        0   \n\n       n_r_SNOWDAS_SolidPrecip_kgpersquarem10InPast  \\\n8087                                              0   \n17256                                             0   \n12637                                             3   \n17425                                            46   \n10113                                             0   \n\n       n_r_SNOWDAS_LiquidPrecip_kgpersquarem10InPast  \\\n8087                                               0   \n17256                                            282   \n12637                                              5   \n17425                                              4   \n10113                                              0   \n\n       n_r_SNOWDAS_SnowpackAveTemp_k10InPast  \n8087                                     265  \n17256                                      0  \n12637                                    273  \n17425                                    273  \n10113                                    273  \n\n[5 rows x 295 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_f_APCPsurface1HourForecast</th>\n      <th>n_f_10mWindSpeed1HourForecast</th>\n      <th>n_f_APCPsurface2HourForecast</th>\n      <th>n_f_10mWindSpeed2HourForecast</th>\n      <th>n_f_APCPsurface3HourForecast</th>\n      <th>n_f_10mWindSpeed3HourForecast</th>\n      <th>n_f_APCPsurface4HourForecast</th>\n      <th>n_f_10mWindSpeed4HourForecast</th>\n      <th>n_f_APCPsurface5HourForecast</th>\n      <th>n_f_10mWindSpeed5HourForecast</th>\n      <th>...</th>\n      <th>n_r_Prev1dayMinTemp10InPast</th>\n      <th>n_r_Prev1DayPrecip10InPast</th>\n      <th>n_r_Prev24HoursPrecipAsRainTotalIn10InPast</th>\n      <th>n_r_SNOWDAS_SnowDepth_mm10InPast</th>\n      <th>n_r_SNOWDAS_SWE_mm10InPast</th>\n      <th>n_r_SNOWDAS_SnowmeltRunoff_micromm10InPast</th>\n      <th>n_r_SNOWDAS_Sublimation_micromm10InPast</th>\n      <th>n_r_SNOWDAS_SolidPrecip_kgpersquarem10InPast</th>\n      <th>n_r_SNOWDAS_LiquidPrecip_kgpersquarem10InPast</th>\n      <th>n_r_SNOWDAS_SnowpackAveTemp_k10InPast</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8087</th>\n      <td>0.000</td>\n      <td>5.003431</td>\n      <td>0.000</td>\n      <td>4.714842</td>\n      <td>0.000</td>\n      <td>4.466812</td>\n      <td>0.000</td>\n      <td>3.891302</td>\n      <td>0.000</td>\n      <td>3.608659</td>\n      <td>...</td>\n      <td>17.96</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>179</td>\n      <td>38</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>265</td>\n    </tr>\n    <tr>\n      <th>17256</th>\n      <td>0.250</td>\n      <td>1.521547</td>\n      <td>0.375</td>\n      <td>1.485751</td>\n      <td>1.125</td>\n      <td>0.849602</td>\n      <td>2.625</td>\n      <td>0.214329</td>\n      <td>4.625</td>\n      <td>0.428978</td>\n      <td>...</td>\n      <td>28.58</td>\n      <td>90.625</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>282</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12637</th>\n      <td>5.125</td>\n      <td>5.506617</td>\n      <td>5.375</td>\n      <td>5.804362</td>\n      <td>5.375</td>\n      <td>5.406490</td>\n      <td>5.375</td>\n      <td>5.092266</td>\n      <td>5.500</td>\n      <td>4.548136</td>\n      <td>...</td>\n      <td>28.76</td>\n      <td>59.875</td>\n      <td>0.0</td>\n      <td>37</td>\n      <td>9</td>\n      <td>133</td>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>17425</th>\n      <td>4.625</td>\n      <td>2.886101</td>\n      <td>6.625</td>\n      <td>3.994727</td>\n      <td>6.625</td>\n      <td>3.994727</td>\n      <td>8.500</td>\n      <td>4.588402</td>\n      <td>8.500</td>\n      <td>4.588402</td>\n      <td>...</td>\n      <td>21.92</td>\n      <td>339.500</td>\n      <td>0.0</td>\n      <td>543</td>\n      <td>142</td>\n      <td>1064</td>\n      <td>4</td>\n      <td>46</td>\n      <td>4</td>\n      <td>273</td>\n    </tr>\n    <tr>\n      <th>10113</th>\n      <td>0.000</td>\n      <td>4.083557</td>\n      <td>0.000</td>\n      <td>3.985551</td>\n      <td>0.000</td>\n      <td>3.985551</td>\n      <td>0.000</td>\n      <td>4.181581</td>\n      <td>0.000</td>\n      <td>4.181581</td>\n      <td>...</td>\n      <td>0.68</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>2266</td>\n      <td>665</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>273</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 295 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_n = df[input_numeric_columns]\n",
    "X = X_n\n",
    "\n",
    "yColumns = ['o_day1DangerAboveTreeline']\n",
    "yColumnlist.append('o_day1DangerAboveTreeline')\n",
    "yAbove=df[yColumns + metadata_columns]\n",
    "X_Above_train, X_Above_test, y_Above_train, y_Above_test = train_test_split(X, yAbove, stratify=yAbove[\"o_day1DangerAboveTreeline\"], test_size=0.20, random_state=1)\n",
    "X_Above_train, X_Above_val, y_Above_train, y_Above_val = train_test_split(X_Above_train, y_Above_train, stratify=y_Above_train['o_day1DangerAboveTreeline'], test_size=0.20, random_state=1)\n",
    "outputList.append(y_Above_train)\n",
    "\n",
    "yNearColumn = ['o_day1DangerNearTreeline']\n",
    "yColumnlist.append('o_day1DangerNearTreeline')\n",
    "yNear=df[yNearColumn+metadata_columns]\n",
    "X_Near_train, X_Near_test, y_Near_train, y_Near_test = train_test_split(X, yNear, stratify=yNear['o_day1DangerNearTreeline'], test_size=0.20, random_state=1)\n",
    "X_Near_train, X_Near_val, y_Near_train, y_Near_val = train_test_split(X_Near_train, y_Near_train, stratify=y_Near_train['o_day1DangerNearTreeline'], test_size=.20, random_state=1)\n",
    "outputList.append(y_Near_train)\n",
    "\n",
    "yBelowColumn = ['o_day1DangerBelowTreeline']\n",
    "yColumnlist.append('o_day1DangerBelowTreeline')\n",
    "yBelow=df[yBelowColumn+metadata_columns]\n",
    "X_Below_train, X_Below_test, y_Below_train, y_Below_test = train_test_split(X, yBelow, stratify=yBelow['o_day1DangerBelowTreeline'], test_size=0.20, random_state=1)\n",
    "X_Below_train, X_Below_val, y_Below_train, y_Below_val = train_test_split(X_Below_train, y_Below_train, stratify=y_Below_train['o_day1DangerBelowTreeline'], test_size=0.20, random_state=1)\n",
    "outputList.append(y_Below_train)\n",
    "\n",
    "roseColumn = ['o_problemRose']\n",
    "yColumnlist.append('o_problemRose')\n",
    "roseInfo = df[roseColumn+metadata_columns]\n",
    "x_Rose_train, x_Rose_test, y_Rose_train, y_Rose_test = train_test_split(X, roseInfo, stratify=roseInfo['o_problemRose'], test_size=.20, random_state=1)\n",
    "x_Rose_train, x_Rose_val, y_Rose_train, y_Rose_val = train_test_split(x_Rose_train, y_Rose_train, stratify=y_Rose_train['o_problemRose'], test_size=.20, random_state=1)\n",
    "outputList.append(y_Rose_train)\n",
    "\n",
    "sizeColumn = ['o_problemSize']\n",
    "yColumnlist.append('o_problemSize')\n",
    "sizeInfo = df[sizeColumn + metadata_columns]\n",
    "x_Size_train, x_Size_test, y_Size_train, y_Size_test = train_test_split(X, sizeInfo, stratify=sizeInfo['o_problemSize'], test_size=.20, random_state=1)\n",
    "x_Size_train, x_Size_val, y_Size_train, y_Size_val = train_test_split(x_Size_train, y_Size_train, stratify=y_Size_train['o_problemSize'], test_size=.20, random_state=1)\n",
    "outputList.append(y_Size_train)\n",
    "\n",
    "hazardColumn = ['o_problemHazard']\n",
    "yColumnlist.append('o_problemHazard')\n",
    "hazardInfo = df[hazardColumn + metadata_columns]\n",
    "x_Hazard_train, x_Hazard_test, y_Hazard_train, y_Hazard_test = train_test_split(X, hazardInfo, stratify=hazardInfo['o_problemHazard'], test_size=.20, random_state=1)\n",
    "x_Hazard_train, x_Hazard_val, y_Hazard_train, y_Hazard_val = train_test_split(x_Hazard_train, y_Hazard_train, stratify=y_Hazard_train['o_problemHazard'], test_size=.20, random_state=1)\n",
    "outputList.append(y_Hazard_train)\n",
    "\n",
    "freqColumn = ['o_problemLikelihood']\n",
    "yColumnlist.append('o_problemLikelihood')\n",
    "freqInfo = df[freqColumn + metadata_columns]\n",
    "x_Freq_train, x_Freq_test, y_Freq_train, y_Freq_test = train_test_split(X, freqInfo, stratify=freqInfo['o_problemLikelihood'], test_size=.20, random_state=1)\n",
    "x_Freq_train, x_Freq_val, y_Freq_train, y_Freq_val = train_test_split(x_Freq_train, y_Freq_train, stratify=y_Freq_train['o_problemLikelihood'], test_size=.20, random_state=1)\n",
    "outputList.append(y_Freq_train)\n",
    "\n",
    "\n",
    "print(len(X_Below_train), 'train examples')\n",
    "print(len(X_Below_val), 'validation examples')\n",
    "\n",
    "y_Below_train.head()\n",
    "X_Below_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for finding labels for model prediction\n",
    "\n",
    "def add_labels(frame, column):\n",
    "    labels = []\n",
    "    for index, row in frame.iterrows():\n",
    "        if row[column] not in labels:\n",
    "            labels.append(row[column])\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "for i in range(0, 7):\n",
    "    label_list.append(add_labels(outputList[i], yColumnlist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the labels to categorical labels for tensorflow\n",
    "\n",
    "y_Below_train['o_day1DangerBelowTreeline'] = pd.Categorical(y_Below_train['o_day1DangerBelowTreeline'])\n",
    "y_Below_train['o_day1DangerBelowTreeline'] = y_Below_train.o_day1DangerBelowTreeline.cat.codes\n",
    "\n",
    "y_Below_test['o_day1DangerBelowTreeline'] = pd.Categorical(y_Below_test['o_day1DangerBelowTreeline'])\n",
    "y_Below_test['o_day1DangerBelowTreeline'] = y_Below_test.o_day1DangerBelowTreeline.cat.codes\n",
    "\n",
    "y_Below_val['o_day1DangerBelowTreeline'] = pd.Categorical(y_Below_val['o_day1DangerBelowTreeline'])\n",
    "y_Below_val['o_day1DangerBelowTreeline'] = y_Below_val.o_day1DangerBelowTreeline.cat.codes\n",
    "\n",
    "y_Above_train['o_day1DangerAboveTreeline'] = pd.Categorical(y_Above_train['o_day1DangerAboveTreeline'])\n",
    "y_Above_train['o_day1DangerAboveTreeline'] = y_Above_train.o_day1DangerAboveTreeline.cat.codes\n",
    "\n",
    "y_Above_val['o_day1DangerAboveTreeline'] = pd.Categorical(y_Above_val['o_day1DangerAboveTreeline'])\n",
    "y_Above_val['o_day1DangerAboveTreeline'] = y_Above_val.o_day1DangerAboveTreeline.cat.codes\n",
    "\n",
    "y_Near_train['o_day1DangerNearTreeline'] = pd.Categorical(y_Near_train['o_day1DangerNearTreeline'])\n",
    "y_Near_train['o_day1DangerNearTreeline'] = y_Near_train.o_day1DangerNearTreeline.cat.codes\n",
    "\n",
    "y_Near_val['o_day1DangerNearTreeline'] = pd.Categorical(y_Near_val['o_day1DangerNearTreeline'])\n",
    "y_Near_val['o_day1DangerNearTreeline'] = y_Near_val.o_day1DangerNearTreeline.cat.codes\n",
    "\n",
    "y_Rose_train['o_problemRose'] = pd.Categorical(y_Rose_train['o_problemRose'])\n",
    "y_Rose_train['o_problemRose'] = y_Rose_train.o_problemRose.cat.codes\n",
    "\n",
    "y_Rose_val['o_problemRose'] = pd.Categorical(y_Rose_val['o_problemRose'])\n",
    "y_Rose_val['o_problemRose'] = y_Rose_val.o_problemRose.cat.codes\n",
    "\n",
    "y_Hazard_train['o_problemHazard'] = pd.Categorical(y_Hazard_train['o_problemHazard'])\n",
    "y_Hazard_train['o_problemHazard'] = y_Hazard_train.o_problemHazard.cat.codes\n",
    "\n",
    "y_Hazard_val['o_problemHazard'] = pd.Categorical(y_Hazard_val['o_problemHazard'])\n",
    "y_Hazard_val['o_problemHazard'] = y_Hazard_val.o_problemHazard.cat.codes\n",
    "\n",
    "y_Size_train['o_problemSize'] = pd.Categorical(y_Size_train['o_problemSize'])\n",
    "y_Size_train['o_problemSize'] = y_Size_train.o_problemSize.cat.codes\n",
    "\n",
    "y_Size_val['o_problemSize'] = pd.Categorical(y_Size_val['o_problemSize'])\n",
    "y_Size_val['o_problemSize'] = y_Size_val.o_problemSize.cat.codes\n",
    "\n",
    "y_Freq_train['o_problemLikelihood'] = pd.Categorical(y_Freq_train['o_problemLikelihood'])\n",
    "y_Freq_train['o_problemLikelihood'] = y_Freq_train.o_problemLikelihood.cat.codes\n",
    "\n",
    "y_Freq_val['o_problemLikelihood'] = pd.Categorical(y_Freq_val['o_problemLikelihood'])\n",
    "y_Freq_val['o_problemLikelihood'] = y_Freq_val.o_problemLikelihood.cat.codes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[  0.75         5.74799913   0.75         5.43390396   1.875\n   5.57379631   3.625        5.20802817   6.           4.96161835\n   6.75         4.87442496   0.           4.74319438   0.\n   5.03755331   0.           5.01358318   0.5          5.45263161\n   1.875        5.49941623   3.75         5.76237833   4.625\n   5.79010017   5.25         5.89815468   6.875        6.34529174\n   8.           6.8208409   10.125        6.37065933   0.\n   3.77559724   1.           5.64201582   1.25         5.86784748\n   1.25         5.86272825   1.25         5.18192772   1.5\n   4.89665551  38.48         6.8208409   77.          32.72\n  34.7          5.5235438   61.75         0.          -3.\n  -0.4         38.48         6.8208409   18.32        38.48\n   6.8208409   12.02        35.6          6.08899964  18.86\n   0.875        0.           2.88         0.           0.\n   0.           0.         -10.           4.           0.\n 273.          78.          -1.          -4.           2.\n  35.6          6.08899964  14.72        35.6          6.77462338\n  12.02        30.38         2.36052519  18.32         0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.          79.          -1.\n  -5.           2.          30.38         6.77462338  12.02\n  30.38         6.77462338  12.02        29.48         5.25206753\n  14.72         0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n  80.          -1.          -4.           1.          29.48\n   6.77462338  12.02        31.64         6.77462338  12.02\n  24.8          6.77462338  12.02         0.           0.\n   0.           0.           0.           0.           0.\n   0.          80.          -1.          -4.           1.\n  29.48         6.77462338  12.02        31.64         6.77462338\n  12.02        24.8          6.77462338  12.02         0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.          80.          -1.\n  -4.           1.          29.48         6.77462338  12.02\n  31.64         6.77462338  12.02        24.8          6.77462338\n  12.02         0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n  80.          -1.          -4.           1.          29.48\n   6.77462338  12.02        31.64         6.77462338  12.02\n  24.8          6.77462338  12.02         0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.          80.          -1.          -4.\n   1.          29.48         6.77462338  12.02        31.64\n   6.77462338  12.02        24.8          6.77462338  12.02\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.          80.\n  -1.          -4.           1.          29.48         6.77462338\n  12.02        31.64         6.77462338  12.02        24.8\n   6.77462338  12.02         0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.          80.          -1.          -4.           1.\n  29.48         6.77462338  12.02        31.64         6.77462338\n  12.02        24.8          6.77462338  12.02         0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.          80.          -1.\n  -4.           1.          29.48         6.77462338  12.02\n  31.64         6.77462338  12.02        24.8          6.77462338\n  12.02         0.           0.           0.           0.\n   0.           0.           0.           0.           0.        ]\n"
    }
   ],
   "source": [
    "#data used to predict the model prediction function\n",
    "\n",
    "test_x = X_Below_test.to_numpy()\n",
    "test_unit = test_x[42]\n",
    "print(test_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into format for input to sequential NN\n",
    "\n",
    "def df_to_dataset(dataframe, labels, labelName):\n",
    "    x_input = dataframe.to_numpy()\n",
    "    temp = labels.copy()\n",
    "    targets = temp.pop(labelName)\n",
    "    y_input = targets.values\n",
    "    return x_input, y_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all the data sets for the NN model\n",
    "#Incorperate this function into class to make it smoother\n",
    "\n",
    "X_Below_train_ds, y_Below_train_ds = df_to_dataset(X_Below_train,  y_Below_train, 'o_day1DangerBelowTreeline')\n",
    "X_Below_test_ds, y_Below_test_ds = df_to_dataset(X_Below_test, y_Below_test, 'o_day1DangerBelowTreeline')\n",
    "X_Below_val_ds, y_Below_val_ds = df_to_dataset(X_Below_val, y_Below_val, 'o_day1DangerBelowTreeline')\n",
    "\n",
    "X_Above_train_ds, y_Above_train_ds = df_to_dataset(X_Above_train, y_Above_train, 'o_day1DangerAboveTreeline')\n",
    "X_Above_test_ds, y_Above_test_ds = df_to_dataset(X_Above_test, y_Above_test, 'o_day1DangerAboveTreeline')\n",
    "X_Above_val_ds, y_Above_val_ds = df_to_dataset(X_Above_val, y_Above_val, 'o_day1DangerAboveTreeline')\n",
    "\n",
    "x_Rose_train_ds, y_Rose_train_ds = df_to_dataset(x_Rose_train, y_Rose_train, 'o_problemRose')\n",
    "x_Rose_val_ds, y_Rose_val_ds = df_to_dataset(x_Rose_val, y_Rose_val, 'o_problemRose')\n",
    "\n",
    "\n",
    "X_Near_train_ds, y_Near_train_ds = df_to_dataset(X_Near_train, y_Near_train, 'o_day1DangerNearTreeline')\n",
    "X_Near_val_ds, y_Near_val_ds = df_to_dataset(X_Near_val, y_Near_val, 'o_day1DangerNearTreeline')\n",
    "\n",
    "x_Hazard_train_ds, y_Hazard_train_ds = df_to_dataset(x_Hazard_train, y_Hazard_train, 'o_problemHazard')\n",
    "x_Hazard_val_ds, y_Hazard_val_ds = df_to_dataset(x_Hazard_val, y_Hazard_val, 'o_problemHazard')\n",
    "\n",
    "x_Size_train_ds, y_Size_train_ds = df_to_dataset(x_Size_train, y_Size_train, 'o_problemSize')\n",
    "x_Size_val_ds, y_Size_val_ds = df_to_dataset(x_Size_val, y_Size_val, 'o_problemSize')\n",
    "\n",
    "x_Freq_train_ds, y_Freq_train_ds = df_to_dataset(x_Freq_train, y_Freq_train, 'o_problemLikelihood')\n",
    "x_Freq_val_ds, y_Freq_val_ds = df_to_dataset(x_Freq_val, y_Freq_val, 'o_problemLikelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input = np.copy(X_Below_test_ds[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 1)\n"
    }
   ],
   "source": [
    "prediction2 = model_Below.predict(predict_Input)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ds = X_Above_train_ds2.batch(1495)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples, validate on 3015 samples\nEpoch 1/50\n12057/12057 [==============================] - 1s 75us/sample - loss: 16.0421 - accuracy: 0.6346 - val_loss: 7.7354 - val_accuracy: 0.6053\nEpoch 2/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 4.8131 - accuracy: 0.6963 - val_loss: 3.7389 - val_accuracy: 0.7350\nEpoch 3/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 2.4864 - accuracy: 0.7235 - val_loss: 2.3605 - val_accuracy: 0.7217\nEpoch 4/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 1.7291 - accuracy: 0.7412 - val_loss: 2.3332 - val_accuracy: 0.7227\nEpoch 5/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 1.3929 - accuracy: 0.7523 - val_loss: 1.6835 - val_accuracy: 0.7224\nEpoch 6/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.0299 - accuracy: 0.7663 - val_loss: 1.3596 - val_accuracy: 0.7609\nEpoch 7/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.8545 - accuracy: 0.7796 - val_loss: 1.5728 - val_accuracy: 0.6454\nEpoch 8/50\n12057/12057 [==============================] - 1s 59us/sample - loss: 0.7582 - accuracy: 0.7851 - val_loss: 1.0951 - val_accuracy: 0.7506\nEpoch 9/50\n12057/12057 [==============================] - 1s 58us/sample - loss: 0.7880 - accuracy: 0.7844 - val_loss: 1.0904 - val_accuracy: 0.7801\nEpoch 10/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.6858 - accuracy: 0.7905 - val_loss: 1.2808 - val_accuracy: 0.7569\nEpoch 11/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.5971 - accuracy: 0.8060 - val_loss: 1.0290 - val_accuracy: 0.7725\nEpoch 12/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.5980 - accuracy: 0.8087 - val_loss: 0.9608 - val_accuracy: 0.7841\nEpoch 13/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.5554 - accuracy: 0.8087 - val_loss: 0.8767 - val_accuracy: 0.7874\nEpoch 14/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.5350 - accuracy: 0.8057 - val_loss: 1.1082 - val_accuracy: 0.6786\nEpoch 15/50\n12057/12057 [==============================] - 1s 59us/sample - loss: 0.5124 - accuracy: 0.8117 - val_loss: 0.7046 - val_accuracy: 0.7960\nEpoch 16/50\n12057/12057 [==============================] - 1s 61us/sample - loss: 0.5284 - accuracy: 0.8126 - val_loss: 0.8326 - val_accuracy: 0.7758\nEpoch 17/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.4783 - accuracy: 0.8275 - val_loss: 0.7600 - val_accuracy: 0.7711\nEpoch 18/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4505 - accuracy: 0.8274 - val_loss: 0.6968 - val_accuracy: 0.7818\nEpoch 19/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4253 - accuracy: 0.8391 - val_loss: 0.7896 - val_accuracy: 0.7930\nEpoch 20/50\n12057/12057 [==============================] - 1s 58us/sample - loss: 0.4917 - accuracy: 0.8273 - val_loss: 0.7318 - val_accuracy: 0.7950\nEpoch 21/50\n12057/12057 [==============================] - 1s 57us/sample - loss: 0.4653 - accuracy: 0.8295 - val_loss: 0.7952 - val_accuracy: 0.7695\nEpoch 22/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.3933 - accuracy: 0.8503 - val_loss: 0.6836 - val_accuracy: 0.8070\nEpoch 23/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.3812 - accuracy: 0.8529 - val_loss: 0.6874 - val_accuracy: 0.7990\nEpoch 24/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4077 - accuracy: 0.8485 - val_loss: 0.7053 - val_accuracy: 0.7818\nEpoch 25/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.4209 - accuracy: 0.8415 - val_loss: 0.7263 - val_accuracy: 0.7917\nEpoch 26/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4226 - accuracy: 0.8463 - val_loss: 0.6221 - val_accuracy: 0.8093\nEpoch 27/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.3683 - accuracy: 0.8584 - val_loss: 0.5639 - val_accuracy: 0.8070\nEpoch 28/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3614 - accuracy: 0.8611 - val_loss: 0.5509 - val_accuracy: 0.8229\nEpoch 29/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.3254 - accuracy: 0.8687 - val_loss: 0.5912 - val_accuracy: 0.8192\nEpoch 30/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3244 - accuracy: 0.8703 - val_loss: 0.5107 - val_accuracy: 0.8318\nEpoch 31/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3332 - accuracy: 0.8695 - val_loss: 0.6680 - val_accuracy: 0.8255\nEpoch 32/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3376 - accuracy: 0.8726 - val_loss: 0.7591 - val_accuracy: 0.7884\nEpoch 33/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3105 - accuracy: 0.8757 - val_loss: 0.6089 - val_accuracy: 0.8216\nEpoch 34/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2954 - accuracy: 0.8805 - val_loss: 0.5688 - val_accuracy: 0.8299\nEpoch 35/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3129 - accuracy: 0.8826 - val_loss: 0.5875 - val_accuracy: 0.8272\nEpoch 36/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3148 - accuracy: 0.8761 - val_loss: 0.5397 - val_accuracy: 0.8342\nEpoch 37/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2827 - accuracy: 0.8849 - val_loss: 0.4866 - val_accuracy: 0.8507\nEpoch 38/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2572 - accuracy: 0.8969 - val_loss: 0.5472 - val_accuracy: 0.8375\nEpoch 39/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2580 - accuracy: 0.8929 - val_loss: 0.5437 - val_accuracy: 0.8381\nEpoch 40/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2560 - accuracy: 0.8927 - val_loss: 0.5973 - val_accuracy: 0.8209\nEpoch 41/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3060 - accuracy: 0.8841 - val_loss: 0.5273 - val_accuracy: 0.8362\nEpoch 42/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2580 - accuracy: 0.8941 - val_loss: 0.5848 - val_accuracy: 0.8425\nEpoch 43/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2752 - accuracy: 0.8971 - val_loss: 0.4810 - val_accuracy: 0.8461\nEpoch 44/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2993 - accuracy: 0.8931 - val_loss: 0.4643 - val_accuracy: 0.8570\nEpoch 45/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.2558 - accuracy: 0.8984 - val_loss: 0.5531 - val_accuracy: 0.8481\nEpoch 46/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2318 - accuracy: 0.9036 - val_loss: 0.5220 - val_accuracy: 0.8491\nEpoch 47/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2172 - accuracy: 0.9085 - val_loss: 0.4422 - val_accuracy: 0.8683\nEpoch 48/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2343 - accuracy: 0.9084 - val_loss: 0.4848 - val_accuracy: 0.8468\nEpoch 49/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2412 - accuracy: 0.9020 - val_loss: 0.4677 - val_accuracy: 0.8640\nEpoch 50/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2240 - accuracy: 0.9080 - val_loss: 0.4809 - val_accuracy: 0.8584\n"
    }
   ],
   "source": [
    "modelBelow = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4)\n",
    "])\n",
    "\n",
    "modelBelow.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "BelowInfo = modelBelow.fit(X_Below_train_ds, y_Below_train_ds, validation_data=(X_Below_val_ds, y_Below_val_ds), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3768\n<class 'numpy.ndarray'>\n<class 'numpy.ndarray'>\n295\n295\n"
    }
   ],
   "source": [
    "\n",
    "print(len(test_x))\n",
    "test_array = np.array([test_x[42]])\n",
    "print(type(test_array))\n",
    "print(type(test_x))\n",
    "print(len(test_x[0]))\n",
    "print(len(test_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictBelow = modelBelow.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3768, 4)\n"
    }
   ],
   "source": [
    "print(predictBelow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ -1.2685325,  10.595232 ,   5.1700206, -76.73752  ]],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "modelBelow.predict(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'loss': [21.009884265343764, 5.433158868539884, 3.5972703239845973, 2.45016842894148, 1.6507975967421582], 'accuracy': [0.63000745, 0.70175004, 0.716845, 0.7331011, 0.7487766]}\n[0.63000745, 0.70175004, 0.716845, 0.7331011, 0.7487766]\n"
    }
   ],
   "source": [
    "print(BelowInfo.history)\n",
    "print(BelowInfo.history['accuracy'])\n",
    "BelowAccuracyList = BelowInfo.history['accuracy']\n",
    "BLoss = BelowInfo.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBelow.save('BelowTreeline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.63000745, 0.70175004, 0.716845, 0.7331011, 0.7487766], [21.009884265343764, 5.433158868539884, 3.5972703239845973, 2.45016842894148, 1.6507975967421582]]\n"
    }
   ],
   "source": [
    "import csv\n",
    "exportInfo = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(BelowExport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples, validate on 3015 samples\nEpoch 1/50\n12057/12057 [==============================] - 1s 66us/sample - loss: 23.7265 - accuracy: 0.6123 - val_loss: 6.0700 - val_accuracy: 0.7028\nEpoch 2/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 5.6300 - accuracy: 0.6903 - val_loss: 6.6115 - val_accuracy: 0.6833\nEpoch 3/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 3.8947 - accuracy: 0.7130 - val_loss: 3.1013 - val_accuracy: 0.7347\nEpoch 4/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 2.4277 - accuracy: 0.7399 - val_loss: 2.1368 - val_accuracy: 0.7423\nEpoch 5/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 1.9353 - accuracy: 0.7474 - val_loss: 2.5149 - val_accuracy: 0.6949\nEpoch 6/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 1.5199 - accuracy: 0.7631 - val_loss: 1.6495 - val_accuracy: 0.7194\nEpoch 7/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 1.0306 - accuracy: 0.7866 - val_loss: 1.3550 - val_accuracy: 0.7526\nEpoch 8/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 1.1100 - accuracy: 0.7839 - val_loss: 1.2903 - val_accuracy: 0.7410\nEpoch 9/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.9055 - accuracy: 0.7886 - val_loss: 1.1172 - val_accuracy: 0.7648\nEpoch 10/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.7509 - accuracy: 0.8043 - val_loss: 0.9522 - val_accuracy: 0.7738\nEpoch 11/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.6846 - accuracy: 0.8131 - val_loss: 1.0403 - val_accuracy: 0.7954\nEpoch 12/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.6665 - accuracy: 0.8103 - val_loss: 1.0086 - val_accuracy: 0.7711\nEpoch 13/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.7089 - accuracy: 0.8069 - val_loss: 1.3058 - val_accuracy: 0.7519\nEpoch 14/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.7225 - accuracy: 0.7923 - val_loss: 0.8170 - val_accuracy: 0.7930\nEpoch 15/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.5151 - accuracy: 0.8222 - val_loss: 0.7083 - val_accuracy: 0.8056\nEpoch 16/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.5028 - accuracy: 0.8292 - val_loss: 0.8438 - val_accuracy: 0.7771\nEpoch 17/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.5539 - accuracy: 0.8211 - val_loss: 0.6854 - val_accuracy: 0.7857\nEpoch 18/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.4768 - accuracy: 0.8347 - val_loss: 0.8202 - val_accuracy: 0.7897\nEpoch 19/50\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.4793 - accuracy: 0.8393 - val_loss: 0.6282 - val_accuracy: 0.8159\nEpoch 20/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.4334 - accuracy: 0.8500 - val_loss: 0.7506 - val_accuracy: 0.8046\nEpoch 21/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4592 - accuracy: 0.8443 - val_loss: 0.9623 - val_accuracy: 0.8209\nEpoch 22/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4406 - accuracy: 0.8480 - val_loss: 0.6786 - val_accuracy: 0.8159\nEpoch 23/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.3746 - accuracy: 0.8624 - val_loss: 0.6546 - val_accuracy: 0.8226\nEpoch 24/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.3805 - accuracy: 0.8602 - val_loss: 0.5670 - val_accuracy: 0.8292\nEpoch 25/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3544 - accuracy: 0.8730 - val_loss: 0.5500 - val_accuracy: 0.8289\nEpoch 26/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.3426 - accuracy: 0.8723 - val_loss: 0.6938 - val_accuracy: 0.8113\nEpoch 27/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3621 - accuracy: 0.8735 - val_loss: 0.5888 - val_accuracy: 0.8464\nEpoch 28/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.3679 - accuracy: 0.8711 - val_loss: 0.5852 - val_accuracy: 0.8109\nEpoch 29/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2994 - accuracy: 0.8864 - val_loss: 0.4854 - val_accuracy: 0.8494\nEpoch 30/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.3039 - accuracy: 0.8833 - val_loss: 0.5720 - val_accuracy: 0.8285\nEpoch 31/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.3198 - accuracy: 0.8847 - val_loss: 0.6000 - val_accuracy: 0.8106\nEpoch 32/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3399 - accuracy: 0.8796 - val_loss: 0.5774 - val_accuracy: 0.8464\nEpoch 33/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.2922 - accuracy: 0.8933 - val_loss: 0.4985 - val_accuracy: 0.8444\nEpoch 34/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.2716 - accuracy: 0.8955 - val_loss: 0.5048 - val_accuracy: 0.8428\nEpoch 35/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2722 - accuracy: 0.9011 - val_loss: 0.4850 - val_accuracy: 0.8544\nEpoch 36/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2561 - accuracy: 0.8967 - val_loss: 0.5048 - val_accuracy: 0.8600\nEpoch 37/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2503 - accuracy: 0.9051 - val_loss: 0.4760 - val_accuracy: 0.8617\nEpoch 38/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2401 - accuracy: 0.9069 - val_loss: 0.5368 - val_accuracy: 0.8498\nEpoch 39/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2737 - accuracy: 0.9006 - val_loss: 0.5674 - val_accuracy: 0.8511\nEpoch 40/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2721 - accuracy: 0.9012 - val_loss: 0.4981 - val_accuracy: 0.8478\nEpoch 41/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2364 - accuracy: 0.9083 - val_loss: 0.4685 - val_accuracy: 0.8736\nEpoch 42/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2163 - accuracy: 0.9175 - val_loss: 0.5352 - val_accuracy: 0.8633\nEpoch 43/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.2670 - accuracy: 0.9075 - val_loss: 0.5863 - val_accuracy: 0.8557\nEpoch 44/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.2552 - accuracy: 0.9061 - val_loss: 0.5221 - val_accuracy: 0.8657\nEpoch 45/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.2382 - accuracy: 0.9141 - val_loss: 0.5051 - val_accuracy: 0.8756\nEpoch 46/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2207 - accuracy: 0.9150 - val_loss: 0.5853 - val_accuracy: 0.8720\nEpoch 47/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.2130 - accuracy: 0.9198 - val_loss: 0.4710 - val_accuracy: 0.8833\nEpoch 48/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.2145 - accuracy: 0.9235 - val_loss: 0.5196 - val_accuracy: 0.8620\nEpoch 49/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.2453 - accuracy: 0.9112 - val_loss: 0.5615 - val_accuracy: 0.8610\nEpoch 50/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 0.2278 - accuracy: 0.9166 - val_loss: 0.4896 - val_accuracy: 0.8846\n"
    }
   ],
   "source": [
    "modelNear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4)\n",
    "])\n",
    "\n",
    "modelNear.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "NearInfo = modelNear.fit(X_Near_train_ds, y_Near_train_ds, validation_data=(X_Near_val_ds, y_Near_val_ds), epochs=50)\n",
    "\n",
    "modelNear.save('NearTreeline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples, validate on 3015 samples\nEpoch 1/50\n12057/12057 [==============================] - 1s 71us/sample - loss: 18.8458 - accuracy: 0.6048 - val_loss: 10.8470 - val_accuracy: 0.6842\nEpoch 2/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 5.4156 - accuracy: 0.6998 - val_loss: 4.1829 - val_accuracy: 0.7068\nEpoch 3/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 3.5347 - accuracy: 0.7285 - val_loss: 3.1345 - val_accuracy: 0.7065\nEpoch 4/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 2.3480 - accuracy: 0.7558 - val_loss: 2.6830 - val_accuracy: 0.7506\nEpoch 5/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 1.9432 - accuracy: 0.7625 - val_loss: 2.1017 - val_accuracy: 0.7386\nEpoch 6/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 1.4131 - accuracy: 0.7812 - val_loss: 1.5183 - val_accuracy: 0.7711\nEpoch 7/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 1.1088 - accuracy: 0.8082 - val_loss: 1.4403 - val_accuracy: 0.7828\nEpoch 8/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.0270 - accuracy: 0.7961 - val_loss: 1.2846 - val_accuracy: 0.7914\nEpoch 9/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.9226 - accuracy: 0.8068 - val_loss: 1.2156 - val_accuracy: 0.7572\nEpoch 10/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.7636 - accuracy: 0.8195 - val_loss: 1.0042 - val_accuracy: 0.7927\nEpoch 11/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.6423 - accuracy: 0.8307 - val_loss: 1.0219 - val_accuracy: 0.7954\nEpoch 12/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.6514 - accuracy: 0.8260 - val_loss: 1.2618 - val_accuracy: 0.7353\nEpoch 13/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.6427 - accuracy: 0.8204 - val_loss: 1.0123 - val_accuracy: 0.7682\nEpoch 14/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.5705 - accuracy: 0.8274 - val_loss: 0.8995 - val_accuracy: 0.8060\nEpoch 15/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.5917 - accuracy: 0.8266 - val_loss: 0.9165 - val_accuracy: 0.7954\nEpoch 16/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.6007 - accuracy: 0.8305 - val_loss: 0.6750 - val_accuracy: 0.8169\nEpoch 17/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.4169 - accuracy: 0.8512 - val_loss: 0.6617 - val_accuracy: 0.8391\nEpoch 18/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.4224 - accuracy: 0.8588 - val_loss: 0.8547 - val_accuracy: 0.8096\nEpoch 19/50\n12057/12057 [==============================] - 1s 55us/sample - loss: 0.4147 - accuracy: 0.8551 - val_loss: 0.6796 - val_accuracy: 0.8378\nEpoch 20/50\n12057/12057 [==============================] - 1s 59us/sample - loss: 0.3909 - accuracy: 0.8633 - val_loss: 0.7560 - val_accuracy: 0.8325\nEpoch 21/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.3861 - accuracy: 0.8698 - val_loss: 0.5687 - val_accuracy: 0.8600\nEpoch 22/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.3970 - accuracy: 0.8682 - val_loss: 1.0113 - val_accuracy: 0.8249\nEpoch 23/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.4722 - accuracy: 0.8539 - val_loss: 0.6897 - val_accuracy: 0.8279\nEpoch 24/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3528 - accuracy: 0.8763 - val_loss: 0.5660 - val_accuracy: 0.8338\nEpoch 25/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.2866 - accuracy: 0.8933 - val_loss: 0.5942 - val_accuracy: 0.8438\nEpoch 26/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.3354 - accuracy: 0.8867 - val_loss: 0.5192 - val_accuracy: 0.8504\nEpoch 27/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.3247 - accuracy: 0.8850 - val_loss: 0.5139 - val_accuracy: 0.8405\nEpoch 28/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.2667 - accuracy: 0.9063 - val_loss: 0.5055 - val_accuracy: 0.8534\nEpoch 29/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.2943 - accuracy: 0.8994 - val_loss: 0.4496 - val_accuracy: 0.8660\nEpoch 30/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.2240 - accuracy: 0.9166 - val_loss: 0.4672 - val_accuracy: 0.8803\nEpoch 31/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2507 - accuracy: 0.9070 - val_loss: 0.5523 - val_accuracy: 0.8614\nEpoch 32/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.3115 - accuracy: 0.9002 - val_loss: 0.6033 - val_accuracy: 0.8600\nEpoch 33/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3221 - accuracy: 0.8945 - val_loss: 0.4835 - val_accuracy: 0.8607\nEpoch 34/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.2506 - accuracy: 0.9136 - val_loss: 0.4421 - val_accuracy: 0.8789\nEpoch 35/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2469 - accuracy: 0.9137 - val_loss: 0.5118 - val_accuracy: 0.8793\nEpoch 36/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.2231 - accuracy: 0.9172 - val_loss: 0.4521 - val_accuracy: 0.8859\nEpoch 37/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2294 - accuracy: 0.9178 - val_loss: 0.4746 - val_accuracy: 0.8743\nEpoch 38/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.2141 - accuracy: 0.9196 - val_loss: 0.4405 - val_accuracy: 0.8796\nEpoch 39/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2415 - accuracy: 0.9152 - val_loss: 0.5948 - val_accuracy: 0.8756\nEpoch 40/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2536 - accuracy: 0.9123 - val_loss: 0.4894 - val_accuracy: 0.8680\nEpoch 41/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2322 - accuracy: 0.9181 - val_loss: 0.4625 - val_accuracy: 0.8856\nEpoch 42/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.1850 - accuracy: 0.9316 - val_loss: 0.5650 - val_accuracy: 0.8610\nEpoch 43/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2109 - accuracy: 0.9204 - val_loss: 0.4769 - val_accuracy: 0.8882\nEpoch 44/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.1791 - accuracy: 0.9341 - val_loss: 0.3737 - val_accuracy: 0.9005\nEpoch 45/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.1751 - accuracy: 0.9325 - val_loss: 0.4678 - val_accuracy: 0.8793\nEpoch 46/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.1889 - accuracy: 0.9307 - val_loss: 0.4557 - val_accuracy: 0.8899\nEpoch 47/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.2009 - accuracy: 0.9269 - val_loss: 0.5324 - val_accuracy: 0.8786\nEpoch 48/50\n12057/12057 [==============================] - 1s 58us/sample - loss: 0.2181 - accuracy: 0.9192 - val_loss: 0.4932 - val_accuracy: 0.8856\nEpoch 49/50\n12057/12057 [==============================] - 1s 55us/sample - loss: 0.2133 - accuracy: 0.9233 - val_loss: 0.5139 - val_accuracy: 0.8836\nEpoch 50/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.2013 - accuracy: 0.9312 - val_loss: 0.4174 - val_accuracy: 0.8896\n"
    }
   ],
   "source": [
    "modelAbove = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4)\n",
    "])\n",
    "\n",
    "modelAbove.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "AboveInfo = modelAbove.fit(X_Above_train_ds, y_Above_train_ds, validation_data=(X_Above_val_ds, y_Above_val_ds), epochs=50)\n",
    "\n",
    "modelAbove.save('AboveTreeline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples, validate on 3015 samples\nEpoch 1/50\n12057/12057 [==============================] - 1s 66us/sample - loss: 20.4690 - accuracy: 0.5803 - val_loss: 11.2251 - val_accuracy: 0.6342\nEpoch 2/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 6.3378 - accuracy: 0.6667 - val_loss: 4.6343 - val_accuracy: 0.6988\nEpoch 3/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 3.7559 - accuracy: 0.7049 - val_loss: 3.0607 - val_accuracy: 0.7274\nEpoch 4/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 2.5648 - accuracy: 0.7254 - val_loss: 2.8334 - val_accuracy: 0.7025\nEpoch 5/50\n12057/12057 [==============================] - 1s 59us/sample - loss: 1.9210 - accuracy: 0.7416 - val_loss: 2.2825 - val_accuracy: 0.7174\nEpoch 6/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 1.2865 - accuracy: 0.7648 - val_loss: 1.6120 - val_accuracy: 0.7539\nEpoch 7/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 1.2569 - accuracy: 0.7666 - val_loss: 1.3016 - val_accuracy: 0.7642\nEpoch 8/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.9792 - accuracy: 0.7842 - val_loss: 1.1893 - val_accuracy: 0.7605\nEpoch 9/50\n12057/12057 [==============================] - 1s 55us/sample - loss: 0.9607 - accuracy: 0.7895 - val_loss: 1.1045 - val_accuracy: 0.7532\nEpoch 10/50\n12057/12057 [==============================] - 1s 55us/sample - loss: 0.8378 - accuracy: 0.7895 - val_loss: 0.9647 - val_accuracy: 0.7489\nEpoch 11/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 0.7957 - accuracy: 0.7837 - val_loss: 0.7916 - val_accuracy: 0.7841\nEpoch 12/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 0.5887 - accuracy: 0.8125 - val_loss: 0.6383 - val_accuracy: 0.7904\nEpoch 13/50\n12057/12057 [==============================] - 1s 55us/sample - loss: 0.5992 - accuracy: 0.8158 - val_loss: 0.6690 - val_accuracy: 0.8123\nEpoch 14/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.5384 - accuracy: 0.8238 - val_loss: 0.7278 - val_accuracy: 0.8043\nEpoch 15/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.5561 - accuracy: 0.8198 - val_loss: 0.7846 - val_accuracy: 0.7562\nEpoch 16/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.6332 - accuracy: 0.8048 - val_loss: 0.7175 - val_accuracy: 0.8100\nEpoch 17/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.5378 - accuracy: 0.8239 - val_loss: 0.7989 - val_accuracy: 0.7874\nEpoch 18/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.5067 - accuracy: 0.8284 - val_loss: 0.6880 - val_accuracy: 0.7964\nEpoch 19/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.4724 - accuracy: 0.8377 - val_loss: 0.6154 - val_accuracy: 0.7970\nEpoch 20/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4562 - accuracy: 0.8416 - val_loss: 0.5606 - val_accuracy: 0.8242\nEpoch 21/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4227 - accuracy: 0.8508 - val_loss: 0.6177 - val_accuracy: 0.8206\nEpoch 22/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4357 - accuracy: 0.8466 - val_loss: 0.5902 - val_accuracy: 0.8232\nEpoch 23/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.3928 - accuracy: 0.8598 - val_loss: 0.5265 - val_accuracy: 0.8229\nEpoch 24/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3821 - accuracy: 0.8571 - val_loss: 0.4865 - val_accuracy: 0.8285\nEpoch 25/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4144 - accuracy: 0.8516 - val_loss: 0.5361 - val_accuracy: 0.8381\nEpoch 26/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.3757 - accuracy: 0.8604 - val_loss: 0.4724 - val_accuracy: 0.8544\nEpoch 27/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.3648 - accuracy: 0.8643 - val_loss: 0.4779 - val_accuracy: 0.8461\nEpoch 28/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.3599 - accuracy: 0.8673 - val_loss: 0.5555 - val_accuracy: 0.8368\nEpoch 29/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.3503 - accuracy: 0.8709 - val_loss: 0.4885 - val_accuracy: 0.8461\nEpoch 30/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.3042 - accuracy: 0.8850 - val_loss: 0.5431 - val_accuracy: 0.8398\nEpoch 31/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3008 - accuracy: 0.8836 - val_loss: 0.6491 - val_accuracy: 0.8133\nEpoch 32/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.3381 - accuracy: 0.8802 - val_loss: 0.5434 - val_accuracy: 0.8212\nEpoch 33/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.3206 - accuracy: 0.8869 - val_loss: 0.4437 - val_accuracy: 0.8448\nEpoch 34/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.2797 - accuracy: 0.8955 - val_loss: 0.5023 - val_accuracy: 0.8219\nEpoch 35/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.2735 - accuracy: 0.8947 - val_loss: 0.3996 - val_accuracy: 0.8700\nEpoch 36/50\n12057/12057 [==============================] - 1s 59us/sample - loss: 0.2810 - accuracy: 0.8939 - val_loss: 0.4637 - val_accuracy: 0.8527\nEpoch 37/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.2885 - accuracy: 0.8935 - val_loss: 0.4786 - val_accuracy: 0.8461\nEpoch 38/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2762 - accuracy: 0.8996 - val_loss: 0.4222 - val_accuracy: 0.8647\nEpoch 39/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2673 - accuracy: 0.8995 - val_loss: 0.4042 - val_accuracy: 0.8750\nEpoch 40/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2543 - accuracy: 0.9045 - val_loss: 0.4545 - val_accuracy: 0.8590\nEpoch 41/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.2495 - accuracy: 0.9067 - val_loss: 0.3977 - val_accuracy: 0.8779\nEpoch 42/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.2558 - accuracy: 0.9072 - val_loss: 0.4005 - val_accuracy: 0.8670\nEpoch 43/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2478 - accuracy: 0.9127 - val_loss: 0.4453 - val_accuracy: 0.8766\nEpoch 44/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.2498 - accuracy: 0.9058 - val_loss: 0.4402 - val_accuracy: 0.8683\nEpoch 45/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2333 - accuracy: 0.9098 - val_loss: 0.4705 - val_accuracy: 0.8730\nEpoch 46/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.2542 - accuracy: 0.9071 - val_loss: 0.4351 - val_accuracy: 0.8769\nEpoch 47/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.2540 - accuracy: 0.9103 - val_loss: 0.4530 - val_accuracy: 0.8816\nEpoch 48/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2095 - accuracy: 0.9217 - val_loss: 0.4213 - val_accuracy: 0.8799\nEpoch 49/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.2189 - accuracy: 0.9186 - val_loss: 0.3937 - val_accuracy: 0.8816\nEpoch 50/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2175 - accuracy: 0.9208 - val_loss: 0.4614 - val_accuracy: 0.8786\n"
    }
   ],
   "source": [
    "modelFreq = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5)\n",
    "])\n",
    "\n",
    "modelFreq.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "FreqInfo = modelFreq.fit(x_Freq_train_ds, y_Freq_train_ds, validation_data=(x_Freq_val_ds, y_Freq_val_ds), epochs=50)\n",
    "\n",
    "modelFreq.save('likelihood.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples, validate on 3015 samples\nEpoch 1/50\n12057/12057 [==============================] - 1s 77us/sample - loss: 15.4865 - accuracy: 0.7421 - val_loss: 5.4457 - val_accuracy: 0.8179\nEpoch 2/50\n12057/12057 [==============================] - 1s 57us/sample - loss: 4.6076 - accuracy: 0.7810 - val_loss: 3.2238 - val_accuracy: 0.7900\nEpoch 3/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 2.8103 - accuracy: 0.7900 - val_loss: 2.6880 - val_accuracy: 0.7353\nEpoch 4/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 1.7598 - accuracy: 0.8081 - val_loss: 1.8126 - val_accuracy: 0.7433\nEpoch 5/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 1.1857 - accuracy: 0.8232 - val_loss: 1.2828 - val_accuracy: 0.7954\nEpoch 6/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.9774 - accuracy: 0.8279 - val_loss: 1.3270 - val_accuracy: 0.8315\nEpoch 7/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.9055 - accuracy: 0.8296 - val_loss: 1.0796 - val_accuracy: 0.7609\nEpoch 8/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.6291 - accuracy: 0.8466 - val_loss: 0.9076 - val_accuracy: 0.8441\nEpoch 9/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.6229 - accuracy: 0.8483 - val_loss: 0.7393 - val_accuracy: 0.8163\nEpoch 10/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.5396 - accuracy: 0.8555 - val_loss: 0.6867 - val_accuracy: 0.8275\nEpoch 11/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.5306 - accuracy: 0.8511 - val_loss: 0.6750 - val_accuracy: 0.8501\nEpoch 12/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.5598 - accuracy: 0.8456 - val_loss: 0.6500 - val_accuracy: 0.8328\nEpoch 13/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.5120 - accuracy: 0.8551 - val_loss: 0.6519 - val_accuracy: 0.8411\nEpoch 14/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.4661 - accuracy: 0.8572 - val_loss: 0.6081 - val_accuracy: 0.8395\nEpoch 15/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4492 - accuracy: 0.8599 - val_loss: 0.5704 - val_accuracy: 0.8527\nEpoch 16/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4365 - accuracy: 0.8592 - val_loss: 0.5783 - val_accuracy: 0.8325\nEpoch 17/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.4075 - accuracy: 0.8651 - val_loss: 0.4515 - val_accuracy: 0.8570\nEpoch 18/50\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.3797 - accuracy: 0.8721 - val_loss: 0.4228 - val_accuracy: 0.8673\nEpoch 19/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.4114 - accuracy: 0.8607 - val_loss: 0.3935 - val_accuracy: 0.8673\nEpoch 20/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.3588 - accuracy: 0.8702 - val_loss: 0.4183 - val_accuracy: 0.8680\nEpoch 21/50\n12057/12057 [==============================] - 1s 61us/sample - loss: 0.3593 - accuracy: 0.8724 - val_loss: 0.4172 - val_accuracy: 0.8670\nEpoch 22/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.3489 - accuracy: 0.8744 - val_loss: 0.4665 - val_accuracy: 0.8587\nEpoch 23/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.3564 - accuracy: 0.8720 - val_loss: 0.3649 - val_accuracy: 0.8677\nEpoch 24/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.3199 - accuracy: 0.8735 - val_loss: 0.3928 - val_accuracy: 0.8630\nEpoch 25/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.3464 - accuracy: 0.8734 - val_loss: 0.5243 - val_accuracy: 0.8438\nEpoch 26/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.3764 - accuracy: 0.8707 - val_loss: 0.3801 - val_accuracy: 0.8763\nEpoch 27/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.3135 - accuracy: 0.8758 - val_loss: 0.3987 - val_accuracy: 0.8650\nEpoch 28/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.3104 - accuracy: 0.8808 - val_loss: 0.4139 - val_accuracy: 0.8700\nEpoch 29/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.3013 - accuracy: 0.8842 - val_loss: 0.3721 - val_accuracy: 0.8720\nEpoch 30/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2760 - accuracy: 0.8877 - val_loss: 0.3534 - val_accuracy: 0.8816\nEpoch 31/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2783 - accuracy: 0.8892 - val_loss: 0.3729 - val_accuracy: 0.8740\nEpoch 32/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2992 - accuracy: 0.8815 - val_loss: 0.4331 - val_accuracy: 0.8653\nEpoch 33/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2896 - accuracy: 0.8850 - val_loss: 0.4120 - val_accuracy: 0.8633\nEpoch 34/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.2785 - accuracy: 0.8890 - val_loss: 0.3547 - val_accuracy: 0.8803\nEpoch 35/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.2650 - accuracy: 0.8918 - val_loss: 0.3684 - val_accuracy: 0.8826\nEpoch 36/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2590 - accuracy: 0.8941 - val_loss: 0.3835 - val_accuracy: 0.8723\nEpoch 37/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.2620 - accuracy: 0.8976 - val_loss: 0.3610 - val_accuracy: 0.8786\nEpoch 38/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2432 - accuracy: 0.9041 - val_loss: 0.3891 - val_accuracy: 0.8706\nEpoch 39/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2620 - accuracy: 0.8979 - val_loss: 0.3501 - val_accuracy: 0.8839\nEpoch 40/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2438 - accuracy: 0.9015 - val_loss: 0.4238 - val_accuracy: 0.8743\nEpoch 41/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2398 - accuracy: 0.9042 - val_loss: 0.3667 - val_accuracy: 0.8892\nEpoch 42/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2275 - accuracy: 0.9082 - val_loss: 0.4196 - val_accuracy: 0.8842\nEpoch 43/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.2517 - accuracy: 0.8977 - val_loss: 0.3796 - val_accuracy: 0.8866\nEpoch 44/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2332 - accuracy: 0.9062 - val_loss: 0.4005 - val_accuracy: 0.8799\nEpoch 45/50\n12057/12057 [==============================] - 1s 59us/sample - loss: 0.2251 - accuracy: 0.9108 - val_loss: 0.4240 - val_accuracy: 0.8882\nEpoch 46/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.2213 - accuracy: 0.9078 - val_loss: 0.3443 - val_accuracy: 0.8876\nEpoch 47/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2178 - accuracy: 0.9103 - val_loss: 0.3501 - val_accuracy: 0.8849\nEpoch 48/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.2163 - accuracy: 0.9096 - val_loss: 0.3634 - val_accuracy: 0.8932\nEpoch 49/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2289 - accuracy: 0.9103 - val_loss: 0.3471 - val_accuracy: 0.8992\nEpoch 50/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.2192 - accuracy: 0.9145 - val_loss: 0.3627 - val_accuracy: 0.8935\n"
    }
   ],
   "source": [
    "modelSize = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5)\n",
    "])\n",
    "\n",
    "modelSize.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "SizeInfo = modelSize.fit(x_Size_train_ds, y_Size_train_ds, validation_data=(x_Size_val_ds, y_Size_val_ds), epochs=50)\n",
    "\n",
    "modelSize.save('size.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples, validate on 3015 samples\nEpoch 1/50\n12057/12057 [==============================] - 1s 79us/sample - loss: 20.0154 - accuracy: 0.6983 - val_loss: 9.6243 - val_accuracy: 0.7307\nEpoch 2/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 5.1053 - accuracy: 0.7714 - val_loss: 3.6570 - val_accuracy: 0.7284\nEpoch 3/50\n12057/12057 [==============================] - 1s 43us/sample - loss: 2.5609 - accuracy: 0.8151 - val_loss: 2.2601 - val_accuracy: 0.8421\nEpoch 4/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 1.8150 - accuracy: 0.8254 - val_loss: 1.4717 - val_accuracy: 0.8186\nEpoch 5/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 1.4617 - accuracy: 0.8394 - val_loss: 1.5243 - val_accuracy: 0.8328\nEpoch 6/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 1.0090 - accuracy: 0.8598 - val_loss: 1.3698 - val_accuracy: 0.8093\nEpoch 7/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.8428 - accuracy: 0.8636 - val_loss: 0.9314 - val_accuracy: 0.8534\nEpoch 8/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.7937 - accuracy: 0.8708 - val_loss: 1.0090 - val_accuracy: 0.8534\nEpoch 9/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.7565 - accuracy: 0.8695 - val_loss: 0.8180 - val_accuracy: 0.8594\nEpoch 10/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.5613 - accuracy: 0.8797 - val_loss: 0.5713 - val_accuracy: 0.8896\nEpoch 11/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.5211 - accuracy: 0.8815 - val_loss: 0.6155 - val_accuracy: 0.8706\nEpoch 12/50\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.4251 - accuracy: 0.8908 - val_loss: 0.5768 - val_accuracy: 0.8580\nEpoch 13/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3662 - accuracy: 0.9026 - val_loss: 0.4818 - val_accuracy: 0.8945\nEpoch 14/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3913 - accuracy: 0.8981 - val_loss: 0.5175 - val_accuracy: 0.8776\nEpoch 15/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3742 - accuracy: 0.8921 - val_loss: 0.6397 - val_accuracy: 0.8889\nEpoch 16/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.4170 - accuracy: 0.8973 - val_loss: 0.5107 - val_accuracy: 0.8769\nEpoch 17/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.4435 - accuracy: 0.8934 - val_loss: 0.5277 - val_accuracy: 0.8783\nEpoch 18/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3795 - accuracy: 0.8991 - val_loss: 0.4559 - val_accuracy: 0.8922\nEpoch 19/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.3005 - accuracy: 0.9099 - val_loss: 0.3840 - val_accuracy: 0.9055\nEpoch 20/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2437 - accuracy: 0.9231 - val_loss: 0.3995 - val_accuracy: 0.9032\nEpoch 21/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2846 - accuracy: 0.9199 - val_loss: 0.3427 - val_accuracy: 0.9061\nEpoch 22/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.3102 - accuracy: 0.9112 - val_loss: 0.5534 - val_accuracy: 0.8783\nEpoch 23/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2718 - accuracy: 0.9208 - val_loss: 0.3482 - val_accuracy: 0.8988\nEpoch 24/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.2557 - accuracy: 0.9228 - val_loss: 0.3099 - val_accuracy: 0.9201\nEpoch 25/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2205 - accuracy: 0.9268 - val_loss: 0.4152 - val_accuracy: 0.9055\nEpoch 26/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2317 - accuracy: 0.9277 - val_loss: 0.3375 - val_accuracy: 0.9085\nEpoch 27/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2591 - accuracy: 0.9210 - val_loss: 0.4935 - val_accuracy: 0.8846\nEpoch 28/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2376 - accuracy: 0.9277 - val_loss: 0.3434 - val_accuracy: 0.9114\nEpoch 29/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2174 - accuracy: 0.9332 - val_loss: 0.3044 - val_accuracy: 0.9194\nEpoch 30/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.1694 - accuracy: 0.9399 - val_loss: 0.2925 - val_accuracy: 0.9284\nEpoch 31/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.2059 - accuracy: 0.9349 - val_loss: 0.3755 - val_accuracy: 0.9055\nEpoch 32/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.1985 - accuracy: 0.9375 - val_loss: 0.3054 - val_accuracy: 0.9171\nEpoch 33/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.1637 - accuracy: 0.9448 - val_loss: 0.3428 - val_accuracy: 0.9227\nEpoch 34/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2093 - accuracy: 0.9378 - val_loss: 0.3040 - val_accuracy: 0.9214\nEpoch 35/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.2113 - accuracy: 0.9384 - val_loss: 0.3608 - val_accuracy: 0.9274\nEpoch 36/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.1829 - accuracy: 0.9439 - val_loss: 0.3209 - val_accuracy: 0.9237\nEpoch 37/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.1790 - accuracy: 0.9429 - val_loss: 0.2613 - val_accuracy: 0.9227\nEpoch 38/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.1549 - accuracy: 0.9480 - val_loss: 0.2314 - val_accuracy: 0.9320\nEpoch 39/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.1422 - accuracy: 0.9530 - val_loss: 0.2467 - val_accuracy: 0.9333\nEpoch 40/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.1970 - accuracy: 0.9383 - val_loss: 0.2430 - val_accuracy: 0.9423\nEpoch 41/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.1510 - accuracy: 0.9556 - val_loss: 0.2716 - val_accuracy: 0.9337\nEpoch 42/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.1544 - accuracy: 0.9497 - val_loss: 0.2195 - val_accuracy: 0.9453\nEpoch 43/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.1239 - accuracy: 0.9588 - val_loss: 0.3285 - val_accuracy: 0.9267\nEpoch 44/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.1916 - accuracy: 0.9409 - val_loss: 0.2676 - val_accuracy: 0.9267\nEpoch 45/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.1418 - accuracy: 0.9575 - val_loss: 0.2775 - val_accuracy: 0.9383\nEpoch 46/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.1346 - accuracy: 0.9555 - val_loss: 0.4570 - val_accuracy: 0.9081\nEpoch 47/50\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.1333 - accuracy: 0.9565 - val_loss: 0.2316 - val_accuracy: 0.9459\nEpoch 48/50\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.1275 - accuracy: 0.9578 - val_loss: 0.2433 - val_accuracy: 0.9320\nEpoch 49/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.1085 - accuracy: 0.9626 - val_loss: 0.2523 - val_accuracy: 0.9453\nEpoch 50/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.1686 - accuracy: 0.9524 - val_loss: 0.2192 - val_accuracy: 0.9420\n"
    }
   ],
   "source": [
    "modelHaz = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(6)\n",
    "])\n",
    "\n",
    "modelHaz.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "HazInfo = modelHaz.fit(x_Hazard_train_ds, y_Hazard_train_ds,validation_data=(x_Hazard_val_ds, y_Hazard_val_ds), epochs=50)\n",
    "\n",
    "modelHaz.save('hazard.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples, validate on 3015 samples\nEpoch 1/50\n12057/12057 [==============================] - 1s 80us/sample - loss: 36.1969 - accuracy: 0.3335 - val_loss: 11.2063 - val_accuracy: 0.4113\nEpoch 2/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 6.9005 - accuracy: 0.4078 - val_loss: 4.3156 - val_accuracy: 0.3602\nEpoch 3/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 3.2064 - accuracy: 0.3964 - val_loss: 2.8126 - val_accuracy: 0.3708\nEpoch 4/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 2.4678 - accuracy: 0.4048 - val_loss: 2.3973 - val_accuracy: 0.3934\nEpoch 5/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 2.0275 - accuracy: 0.4312 - val_loss: 2.1093 - val_accuracy: 0.4292\nEpoch 6/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 1.8432 - accuracy: 0.4511 - val_loss: 2.0843 - val_accuracy: 0.4252\nEpoch 7/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 1.7396 - accuracy: 0.4705 - val_loss: 1.9897 - val_accuracy: 0.4541\nEpoch 8/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.5953 - accuracy: 0.5070 - val_loss: 1.7276 - val_accuracy: 0.4799\nEpoch 9/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 1.5335 - accuracy: 0.5280 - val_loss: 1.7768 - val_accuracy: 0.4620\nEpoch 10/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 1.4561 - accuracy: 0.5458 - val_loss: 1.6058 - val_accuracy: 0.5453\nEpoch 11/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.3664 - accuracy: 0.5624 - val_loss: 1.6744 - val_accuracy: 0.4842\nEpoch 12/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.2959 - accuracy: 0.5929 - val_loss: 1.4995 - val_accuracy: 0.5701\nEpoch 13/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.2710 - accuracy: 0.6034 - val_loss: 1.4715 - val_accuracy: 0.5705\nEpoch 14/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 1.1994 - accuracy: 0.6094 - val_loss: 1.3985 - val_accuracy: 0.5738\nEpoch 15/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.1378 - accuracy: 0.6304 - val_loss: 1.2475 - val_accuracy: 0.5973\nEpoch 16/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 1.0456 - accuracy: 0.6547 - val_loss: 1.2202 - val_accuracy: 0.6279\nEpoch 17/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 1.0578 - accuracy: 0.6531 - val_loss: 1.1132 - val_accuracy: 0.6647\nEpoch 18/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.9355 - accuracy: 0.6862 - val_loss: 1.0985 - val_accuracy: 0.6680\nEpoch 19/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.9783 - accuracy: 0.6798 - val_loss: 1.1064 - val_accuracy: 0.6444\nEpoch 20/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.8529 - accuracy: 0.7205 - val_loss: 1.0281 - val_accuracy: 0.6998\nEpoch 21/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.8706 - accuracy: 0.7197 - val_loss: 1.0296 - val_accuracy: 0.7124\nEpoch 22/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.8080 - accuracy: 0.7293 - val_loss: 1.0258 - val_accuracy: 0.6929\nEpoch 23/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.8390 - accuracy: 0.7416 - val_loss: 0.9090 - val_accuracy: 0.7343\nEpoch 24/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.7611 - accuracy: 0.7591 - val_loss: 0.9124 - val_accuracy: 0.7237\nEpoch 25/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.7417 - accuracy: 0.7564 - val_loss: 0.8406 - val_accuracy: 0.7290\nEpoch 26/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.6755 - accuracy: 0.7764 - val_loss: 0.8702 - val_accuracy: 0.7343\nEpoch 27/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.6485 - accuracy: 0.7888 - val_loss: 0.8960 - val_accuracy: 0.7416\nEpoch 28/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.6320 - accuracy: 0.7932 - val_loss: 0.8946 - val_accuracy: 0.7466\nEpoch 29/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.5982 - accuracy: 0.8055 - val_loss: 0.7519 - val_accuracy: 0.7781\nEpoch 30/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.5767 - accuracy: 0.8126 - val_loss: 0.9354 - val_accuracy: 0.7559\nEpoch 31/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.6326 - accuracy: 0.7955 - val_loss: 0.7201 - val_accuracy: 0.8013\nEpoch 32/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.5506 - accuracy: 0.8175 - val_loss: 0.8018 - val_accuracy: 0.7804\nEpoch 33/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.5674 - accuracy: 0.8134 - val_loss: 0.7451 - val_accuracy: 0.7887\nEpoch 34/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.5187 - accuracy: 0.8262 - val_loss: 0.7891 - val_accuracy: 0.7814\nEpoch 35/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4934 - accuracy: 0.8336 - val_loss: 0.6827 - val_accuracy: 0.8083\nEpoch 36/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.5131 - accuracy: 0.8340 - val_loss: 0.8010 - val_accuracy: 0.7993\nEpoch 37/50\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4895 - accuracy: 0.8379 - val_loss: 0.6547 - val_accuracy: 0.8196\nEpoch 38/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.5276 - accuracy: 0.8387 - val_loss: 0.7101 - val_accuracy: 0.8000\nEpoch 39/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.4568 - accuracy: 0.8487 - val_loss: 0.7595 - val_accuracy: 0.7930\nEpoch 40/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.4684 - accuracy: 0.8444 - val_loss: 0.6987 - val_accuracy: 0.8199\nEpoch 41/50\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.4897 - accuracy: 0.8346 - val_loss: 0.6781 - val_accuracy: 0.8242\nEpoch 42/50\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4263 - accuracy: 0.8588 - val_loss: 0.6095 - val_accuracy: 0.8269\nEpoch 43/50\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.4235 - accuracy: 0.8615 - val_loss: 0.7902 - val_accuracy: 0.8153\nEpoch 44/50\n12057/12057 [==============================] - 1s 54us/sample - loss: 0.4309 - accuracy: 0.8649 - val_loss: 0.6636 - val_accuracy: 0.8302\nEpoch 45/50\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.4598 - accuracy: 0.8545 - val_loss: 0.7562 - val_accuracy: 0.8076\nEpoch 46/50\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.3817 - accuracy: 0.8692 - val_loss: 0.7007 - val_accuracy: 0.8172\nEpoch 47/50\n12057/12057 [==============================] - 1s 53us/sample - loss: 0.4281 - accuracy: 0.8599 - val_loss: 0.6604 - val_accuracy: 0.8514\nEpoch 48/50\n12057/12057 [==============================] - 1s 58us/sample - loss: 0.4300 - accuracy: 0.8611 - val_loss: 0.6082 - val_accuracy: 0.8474\nEpoch 49/50\n12057/12057 [==============================] - 1s 56us/sample - loss: 0.3967 - accuracy: 0.8683 - val_loss: 0.6226 - val_accuracy: 0.8458\nEpoch 50/50\n12057/12057 [==============================] - 1s 58us/sample - loss: 0.3632 - accuracy: 0.8810 - val_loss: 0.6352 - val_accuracy: 0.8352\n"
    }
   ],
   "source": [
    "modelRose = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32)\n",
    "])\n",
    "\n",
    "modelRose.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "RoseInfo = modelRose.fit(x_Rose_train_ds, y_Rose_train_ds, validation_data=(x_Rose_val_ds, y_Rose_val_ds), epochs=50)\n",
    "\n",
    "modelRose.save('rose.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelHaz = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(8)\n",
    "])\n",
    "\n",
    "modelHaz.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12057 samples\nEpoch 1/100\n12057/12057 [==============================] - 1s 73us/sample - loss: 17.1883 - accuracy: 0.6979\nEpoch 2/100\n12057/12057 [==============================] - 1s 46us/sample - loss: 5.4068 - accuracy: 0.7725\nEpoch 3/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 3.1104 - accuracy: 0.8043\nEpoch 4/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 1.8960 - accuracy: 0.8389\nEpoch 5/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 1.4775 - accuracy: 0.8459\nEpoch 6/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 1.0550 - accuracy: 0.8634\nEpoch 7/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 1.0606 - accuracy: 0.8626\nEpoch 8/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.7721 - accuracy: 0.8752\nEpoch 9/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.7287 - accuracy: 0.8756\nEpoch 10/100\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.7138 - accuracy: 0.8739\nEpoch 11/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.5640 - accuracy: 0.8860\nEpoch 12/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.5908 - accuracy: 0.8851\nEpoch 13/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.4628 - accuracy: 0.8966\nEpoch 14/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.5323 - accuracy: 0.8890\nEpoch 15/100\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.4520 - accuracy: 0.8993\nEpoch 16/100\n12057/12057 [==============================] - 1s 44us/sample - loss: 0.4276 - accuracy: 0.8948\nEpoch 17/100\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.4681 - accuracy: 0.8973\nEpoch 18/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.4140 - accuracy: 0.8981\nEpoch 19/100\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.3116 - accuracy: 0.9105\nEpoch 20/100\n12057/12057 [==============================] - 1s 48us/sample - loss: 0.3462 - accuracy: 0.9060\nEpoch 21/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.3104 - accuracy: 0.9109\nEpoch 22/100\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2830 - accuracy: 0.9171\nEpoch 23/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.2733 - accuracy: 0.9187\nEpoch 24/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.3008 - accuracy: 0.9153\nEpoch 25/100\n12057/12057 [==============================] - 1s 52us/sample - loss: 0.2627 - accuracy: 0.9280\nEpoch 26/100\n12057/12057 [==============================] - 1s 50us/sample - loss: 0.2577 - accuracy: 0.9250\nEpoch 27/100\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.2857 - accuracy: 0.9215\nEpoch 28/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.2667 - accuracy: 0.9212\nEpoch 29/100\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.2523 - accuracy: 0.9278\nEpoch 30/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.2107 - accuracy: 0.9352\nEpoch 31/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.2009 - accuracy: 0.9373\nEpoch 32/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1776 - accuracy: 0.9389\nEpoch 33/100\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.1769 - accuracy: 0.9414\nEpoch 34/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.2209 - accuracy: 0.9395\nEpoch 35/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1802 - accuracy: 0.9416\nEpoch 36/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1579 - accuracy: 0.9492\nEpoch 37/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.1983 - accuracy: 0.9414\nEpoch 38/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.1539 - accuracy: 0.9500\nEpoch 39/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1958 - accuracy: 0.9406\nEpoch 40/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1391 - accuracy: 0.9564\nEpoch 41/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1566 - accuracy: 0.9505\nEpoch 42/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1256 - accuracy: 0.9566\nEpoch 43/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1226 - accuracy: 0.9594\nEpoch 44/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.1478 - accuracy: 0.9523\nEpoch 45/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1694 - accuracy: 0.9511\nEpoch 46/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1364 - accuracy: 0.9554\nEpoch 47/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.1025 - accuracy: 0.9638\nEpoch 48/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1273 - accuracy: 0.9604\nEpoch 49/100\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.1142 - accuracy: 0.9602\nEpoch 50/100\n12057/12057 [==============================] - 1s 47us/sample - loss: 0.1271 - accuracy: 0.9599\nEpoch 51/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1393 - accuracy: 0.9577\nEpoch 52/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1059 - accuracy: 0.9637\nEpoch 53/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.1186 - accuracy: 0.9600\nEpoch 54/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.1307 - accuracy: 0.9598\nEpoch 55/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.0913 - accuracy: 0.9676\nEpoch 56/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1340 - accuracy: 0.9575\nEpoch 57/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1147 - accuracy: 0.9639\nEpoch 58/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1062 - accuracy: 0.9676\nEpoch 59/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.1164 - accuracy: 0.9644\nEpoch 60/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1224 - accuracy: 0.9632\nEpoch 61/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.0923 - accuracy: 0.9674\nEpoch 62/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.1294 - accuracy: 0.9599\nEpoch 63/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.0931 - accuracy: 0.9677\nEpoch 64/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.1012 - accuracy: 0.9679\nEpoch 65/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1782 - accuracy: 0.9594\nEpoch 66/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0926 - accuracy: 0.9692\nEpoch 67/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0948 - accuracy: 0.9677\nEpoch 68/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0917 - accuracy: 0.9682\nEpoch 69/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.0916 - accuracy: 0.9702\nEpoch 70/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1189 - accuracy: 0.9648\nEpoch 71/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1006 - accuracy: 0.9695\nEpoch 72/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.0754 - accuracy: 0.9725\nEpoch 73/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.1021 - accuracy: 0.9679\nEpoch 74/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.0944 - accuracy: 0.9709\nEpoch 75/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.1003 - accuracy: 0.9682\nEpoch 76/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.1100 - accuracy: 0.9686\nEpoch 77/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.0930 - accuracy: 0.9706\nEpoch 78/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0778 - accuracy: 0.9742\nEpoch 79/100\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.1776 - accuracy: 0.9569\nEpoch 80/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0985 - accuracy: 0.9676\nEpoch 81/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.0814 - accuracy: 0.9723\nEpoch 82/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0817 - accuracy: 0.9721\nEpoch 83/100\n12057/12057 [==============================] - 1s 49us/sample - loss: 0.0815 - accuracy: 0.9732\nEpoch 84/100\n12057/12057 [==============================] - 1s 51us/sample - loss: 0.1131 - accuracy: 0.9669\nEpoch 85/100\n12057/12057 [==============================] - 1s 43us/sample - loss: 0.0881 - accuracy: 0.9710\nEpoch 86/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.0704 - accuracy: 0.9759\nEpoch 87/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0718 - accuracy: 0.9785\nEpoch 88/100\n12057/12057 [==============================] - 1s 45us/sample - loss: 0.1139 - accuracy: 0.9680\nEpoch 89/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.0955 - accuracy: 0.9712\nEpoch 90/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.0922 - accuracy: 0.9716\nEpoch 91/100\n12057/12057 [==============================] - 1s 46us/sample - loss: 0.0859 - accuracy: 0.9711\nEpoch 92/100\n12057/12057 [==============================] - 1s 42us/sample - loss: 0.0494 - accuracy: 0.9811\nEpoch 93/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.0761 - accuracy: 0.9755\nEpoch 94/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.0785 - accuracy: 0.9759\nEpoch 95/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.0757 - accuracy: 0.9739\nEpoch 96/100\n12057/12057 [==============================] - 0s 40us/sample - loss: 0.0713 - accuracy: 0.9764\nEpoch 97/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.1475 - accuracy: 0.9593\nEpoch 98/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.1117 - accuracy: 0.9673\nEpoch 99/100\n12057/12057 [==============================] - 0s 39us/sample - loss: 0.0868 - accuracy: 0.9733\nEpoch 100/100\n12057/12057 [==============================] - 0s 41us/sample - loss: 0.0780 - accuracy: 0.9742\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1648ae7d0>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "modelHaz.fit(x_Hazard_train_ds, y_Hazard_train_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportAccuracyInfo = []\n",
    "exportValInfo = []\n",
    "infoList = [BelowInfo, NearInfo, AboveInfo, RoseInfo, SizeInfo, FreqInfo, HazInfo]\n",
    "for item in infoList:\n",
    "    exportAccuracyInfo.append(item.history['accuracy'])\n",
    "    exportValInfo.append(item.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('accuracy.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(exportAccuracyInfo)\n",
    "\n",
    "with open('val.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(exportValInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictBelow = modelBelow.predict(test_x)\n",
    "predictNear = modelNear.predict(test_x)\n",
    "predictAbove = modelAbove.predict(test_x)\n",
    "predictRose = modelRose.predict(test_x)\n",
    "predictFreq = modelFreq.predict(test_x)\n",
    "predictSize = modelSize.predict(test_x)\n",
    "predictHaz = modelHaz.predict(test_x)\n",
    "\n",
    "print(predictNear.shape)\n",
    "print(predictBelow.shape)\n",
    "print(predictNear.shape)\n",
    "print(predictRose.shape)\n",
    "print(predictFreq.shape)\n",
    "print(predictSize.shape)\n",
    "print(predictHaz.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit1cd1a506bf62492f81d9837d3638bb36",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}